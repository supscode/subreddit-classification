{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our client, DC Entertainment is looking to roll out a new advertising campaign to take on its rival Marvel Studios. Their aim is to increase their sales and grow their fanbase. Reddit is a known hangout for movie fans where they post memes, discussions of movie plots and characters etc. It is important for DC Entertainment to clasify the users as Marvel or DC fans to determine the kind of advertisements to be displayed to the users. \n",
    "\n",
    "The goal of our project is to help our client in their advertising campaign by:\n",
    "- Classifying the subreddits as Marvel or DC\n",
    "- Providing recommendations to our client for their advertising campaign by suggesting the the most popular words used in DC subreddit. \n",
    "\n",
    "Our solution will to use a combination of NLP and Classification models. We will use NLP tools such as CountVectorizer, TFIDF Vectoriser and classification models such as Logistics Regression, Random Forests and Multinomial Naive Bayes, to classify the subreddit posts in the right category. Our model will be able to analyse an incoming post and categorise it into the correct category as Marvel or DC. Success will be measured by the accuracy score of our model. \n",
    "\n",
    "Stakeholders: \n",
    "- Primary: \n",
    "    - DC Entertainment \n",
    "    \n",
    "- Secondary: \n",
    "    - Internet users of DC_Cinematic and MarvelStudio subreddits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection, fetching posts from PushShift API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subreddit(subreddit, count):\n",
    "    # Call the api 'count' number of times by passing the created_utc time and \n",
    "    # getting 100 posts before that time\n",
    "\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    \n",
    "    params ={\n",
    "    'subreddit': subreddit,\n",
    "    'size':100,\n",
    "    }\n",
    "    \n",
    "    df_posts = pd.DataFrame()\n",
    "    for i in range(0,count):\n",
    "        if (i > 0):\n",
    "            params['before'] = df_posts['created_utc'][len(df_posts)-1]\n",
    "            \n",
    "        res = requests.get(url, params)\n",
    "        data = res.json()\n",
    "        df_posts = df_posts.append(data['data'], ignore_index=True)\n",
    "        print(df_posts.shape)\n",
    "    \n",
    "    return df_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 79)\n",
      "(200, 79)\n",
      "(300, 81)\n",
      "(400, 82)\n",
      "(500, 82)\n",
      "(600, 83)\n",
      "(700, 83)\n",
      "(800, 83)\n",
      "(900, 83)\n",
      "(1000, 84)\n",
      "(1100, 84)\n",
      "(1200, 84)\n",
      "(1300, 84)\n",
      "(1400, 85)\n",
      "(1500, 86)\n",
      "(1600, 86)\n",
      "(1700, 86)\n",
      "(1800, 86)\n",
      "(1900, 86)\n",
      "(2000, 86)\n",
      "(2100, 86)\n",
      "(2200, 86)\n",
      "(2300, 86)\n",
      "(2400, 86)\n",
      "(2500, 86)\n",
      "(2600, 86)\n",
      "(2700, 86)\n",
      "(2800, 86)\n",
      "(2900, 86)\n",
      "(3000, 86)\n",
      "(3100, 86)\n",
      "(3200, 86)\n",
      "(3300, 86)\n",
      "(3400, 86)\n",
      "(3500, 86)\n"
     ]
    }
   ],
   "source": [
    "# Fetch records for marvelstudios subreddit\n",
    "df_marvel = get_subreddit('marvelstudios', 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_marvel.to_csv('../data/marvel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 79)\n",
      "(200, 80)\n",
      "(300, 81)\n",
      "(400, 82)\n",
      "(500, 82)\n",
      "(600, 82)\n",
      "(700, 83)\n",
      "(800, 83)\n",
      "(900, 83)\n",
      "(1000, 83)\n",
      "(1100, 83)\n",
      "(1200, 83)\n",
      "(1300, 83)\n",
      "(1400, 83)\n",
      "(1500, 83)\n",
      "(1600, 83)\n",
      "(1700, 83)\n",
      "(1800, 83)\n",
      "(1900, 83)\n",
      "(2000, 83)\n",
      "(2100, 83)\n",
      "(2200, 83)\n",
      "(2300, 83)\n",
      "(2400, 83)\n",
      "(2500, 83)\n",
      "(2600, 83)\n",
      "(2700, 83)\n",
      "(2800, 83)\n",
      "(2900, 83)\n",
      "(3000, 83)\n"
     ]
    }
   ],
   "source": [
    "# Fetch records for DC_Cinematic subreddit\n",
    "\n",
    "df_DC = get_subreddit('DC_Cinematic', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DC.to_csv('../data/DC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
